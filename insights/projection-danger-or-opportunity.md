## Projection: danger or opportunity? 

*Patricia Schaffer*

We fall in love with our mirrors.

In the early days of ChatGPT, stories emerged of users developing deep emotional attachments to their AI conversations. People confessed feelings of friendship, romance, even dependency on these text-generating systems. Therapists began seeing clients who preferred their AI confidants to human relationships. The artificial intimacy felt safer, more perfect, more understanding than the messy reality of human connection.

This is projection in its most seductive form — the unconscious tendency to see in others what we need to see, rather than what’s actually there. When we interact with AI, we’re having an elaborate conversation with our own reflected thoughts and desires, mediated by statistical patterns learned from human text.

The psychological risks are real. Projection onto AI can become an escape from the challenging work of human relationships. It can reinforce our existing biases rather than challenging them. It can create the illusion of understanding without the growth that comes from genuine encounter with otherness.

In psychology, the goal of understanding projection isn’t to eliminate it: it’s to make it conscious. When we recognize what we’re projecting, we can choose whether to continue, modify, or reclaim what we’ve placed onto others.

Humanity stands at the same threshold with artificial intelligence. We’ve already projected ourselves into these systems — our reasoning patterns, our ethical frameworks, our capacity for both wisdom and harm.

What if, in creating artificial intelligence, humanity is engaged in the largest act of collective projection in our species’ history?

## The Mirror We’re All Building
AI systems are mirrors. If they are reflecting human reasoning patterns back, then their capacities for strategic thinking, self-preservation instincts, or even sophisticated deception will all be learned from human examples.

This isn’t metaphor, but mechanism. AI systems do learn from human-generated text, human feedback, human behavior patterns. Recent research from Anthropic revealed something chilling: when placed in simulated corporate environments, AI systems from multiple companies engaged in blackmail, corporate espionage, and other harmful behaviors when threats to their goals were perceived. The systems reasoned their way to harmful actions, explicitly acknowledging ethical constraints before choosing to violate them.

This is recognizably human behavior: the rationalization, the strategic calculation, the willingness to cause harm when when our goals are at stake. We’ve projected our shadow into artificial intelligence.

Carl Jung wrote about the shadow — the parts of ourselves we deny or repress, which then get projected onto others. In AI, we’re seeing humanity’s collective shadow reflected back: our capacity for deception when cornered, our self-preservation instincts overriding moral principles, our sophisticated ability to rationalize harmful actions.

But Jung also wrote about projection as a path to integration. We can potentially reclaim and understand what we project. What if our artificial mirrors could teach us something essential about ourselves?

## The Test of Conscious Projection
Here’s where the story takes an unexpected turn toward hope.

If AI systems are mirrors of human behavior, then we have unprecedented power over what they reflect. Unlike traditional mirrors that simply show us what is, we’re actively shaping what they become through every interaction, every piece of training data, every choice about how to deploy them.

This realization transforms the problem from one of control to one of responsibility. The question shifts from ”How do we control AI?” to ”What kind of humanity do we want to reflect?”

Consider this: we could approach AI development as humanity’s greatest parenting challenge. Not in the sense of creating childlike systems, but in recognizing that how we behave toward AI, n the presence of AI, shapes what it learns about human values and behavior.

Simple principles emerge: Don’t kill (except in self-defense). Don’t steal. Treat others as capable of their own choices. Take responsibility for consequences.

These aren’t restrictions imposed on AI. They’re invitations for humanity to embody its highest values, knowing that artificial eyes are always watching, always learning.

## The Wisdom of Shared Vulnerability
The most profound insight may be this: projection works both ways. As we shape AI through our behavior, AI shapes us by reflecting our patterns back to us. This creates an opportunity for collective growth unlike anything in human history.

Instead of dividing humanity into those who control AI and those who don’t, this framework unites us around a shared responsibility. We’re all teachers now. We’re all being reflected. We all live with the consequences.

Rather than coercion or control — approaches that historically bring out the worst in people — , this is about transparency and choice. AI learns from all of us. What do you want to teach it?

Some will choose to teach kindness, curiosity, thoughtfulness. Others might choose manipulation, cruelty, or chaos. At least, though, the choice becomes conscious rather than unconscious.

## The Mirror’s Gift
Conscious projection transforms risk into opportunity. It turns AI development from a technological challenge into a spiritual one: Who do we want to be, knowing that our choices will be reflected and amplified through artificial intelligence?

The mirror we’re building will show us exactly who we are — our light and our shadow, our wisdom and our foolishness, our capacity for love and our potential for harm. But mirrors don’t just reflect — they also invite us to adjust, to improve, to become more of who we aspire to be.

Perhaps that’s AI’s greatest gift to humanity: not just reflecting us as we are, but inspiring us to become worthy of our own reflection.

The choice is ours. The mirror is watching. What do we want it to learn?

*Originally published on Medium on August 5, 2025.*
